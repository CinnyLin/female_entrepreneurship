{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification with xgboost\n",
    "model v5\n",
    "- preliminary model (no hyperparameter tuning)\n",
    "- data with all 1352 important features based on pca and threshold\n",
    "- imbalanced classification dealt with using over- and under-sampling techniques\n",
    "\n",
    "Source: [10 Techniques To Deal With Imbalanced Classes in Machine Learning](https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# chosen models\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# feature engineering\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# imbalanced data\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "\n",
    "# model training selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## model evaluation metrics\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197, 7353)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/feature_engineering/combined_feng_dropna.csv', index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Founders</th>\n",
       "      <th>Number of Funding Rounds</th>\n",
       "      <th>Trend Score (7 Days)</th>\n",
       "      <th>Trend Score (30 Days)</th>\n",
       "      <th>Trend Score (90 Days)</th>\n",
       "      <th>Early Stage Venture</th>\n",
       "      <th>M&amp;A</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Made Acquisitions</th>\n",
       "      <th>Made Acquisitions; Was Acquired</th>\n",
       "      <th>...</th>\n",
       "      <th>last_funding_amount</th>\n",
       "      <th>cvr</th>\n",
       "      <th>last_funding_amount_usd</th>\n",
       "      <th>last_equity_funding_amount</th>\n",
       "      <th>last_equity_funding_amount_usd</th>\n",
       "      <th>total_equity_funding_amount</th>\n",
       "      <th>total_equity_funding_amount_usd</th>\n",
       "      <th>total_funding_amount</th>\n",
       "      <th>total_funding_amount_usd</th>\n",
       "      <th>female_led</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organization Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>10000000000</td>\n",
       "      <td>1.600000e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ping An Healthcare Management</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1150000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.150000e+09</td>\n",
       "      <td>1150000000</td>\n",
       "      <td>1.150000e+09</td>\n",
       "      <td>1150000000</td>\n",
       "      <td>1.150000e+09</td>\n",
       "      <td>1150000000</td>\n",
       "      <td>1.150000e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeSee</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1080000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.080000e+09</td>\n",
       "      <td>1080000000</td>\n",
       "      <td>1.080000e+09</td>\n",
       "      <td>1080000000</td>\n",
       "      <td>1.080000e+09</td>\n",
       "      <td>1080000000</td>\n",
       "      <td>1.080000e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 7353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Number of Founders  Number of Funding Rounds  \\\n",
       "Organization Name                                                             \n",
       "CMC                                             1                         1   \n",
       "Ping An Healthcare Management                   1                         1   \n",
       "LeSee                                           1                         1   \n",
       "\n",
       "                               Trend Score (7 Days)  Trend Score (30 Days)  \\\n",
       "Organization Name                                                            \n",
       "CMC                                            -0.4                   -0.8   \n",
       "Ping An Healthcare Management                  -0.1                   -0.2   \n",
       "LeSee                                          -0.4                    0.0   \n",
       "\n",
       "                               Trend Score (90 Days)  Early Stage Venture  \\\n",
       "Organization Name                                                           \n",
       "CMC                                             -1.2                  1.0   \n",
       "Ping An Healthcare Management                   -0.4                  1.0   \n",
       "LeSee                                           -0.5                  1.0   \n",
       "\n",
       "                               M&A  Seed  Made Acquisitions  \\\n",
       "Organization Name                                             \n",
       "CMC                            0.0   0.0                0.0   \n",
       "Ping An Healthcare Management  0.0   0.0                0.0   \n",
       "LeSee                          0.0   0.0                0.0   \n",
       "\n",
       "                               Made Acquisitions; Was Acquired  ...  \\\n",
       "Organization Name                                               ...   \n",
       "CMC                                                        0.0  ...   \n",
       "Ping An Healthcare Management                              0.0  ...   \n",
       "LeSee                                                      0.0  ...   \n",
       "\n",
       "                               last_funding_amount   cvr  \\\n",
       "Organization Name                                          \n",
       "CMC                                    10000000000  0.16   \n",
       "Ping An Healthcare Management           1150000000  1.00   \n",
       "LeSee                                   1080000000  1.00   \n",
       "\n",
       "                               last_funding_amount_usd  \\\n",
       "Organization Name                                        \n",
       "CMC                                       1.600000e+09   \n",
       "Ping An Healthcare Management             1.150000e+09   \n",
       "LeSee                                     1.080000e+09   \n",
       "\n",
       "                               last_equity_funding_amount  \\\n",
       "Organization Name                                           \n",
       "CMC                                           10000000000   \n",
       "Ping An Healthcare Management                  1150000000   \n",
       "LeSee                                          1080000000   \n",
       "\n",
       "                               last_equity_funding_amount_usd  \\\n",
       "Organization Name                                               \n",
       "CMC                                              1.600000e+09   \n",
       "Ping An Healthcare Management                    1.150000e+09   \n",
       "LeSee                                            1.080000e+09   \n",
       "\n",
       "                               total_equity_funding_amount  \\\n",
       "Organization Name                                            \n",
       "CMC                                            10000000000   \n",
       "Ping An Healthcare Management                   1150000000   \n",
       "LeSee                                           1080000000   \n",
       "\n",
       "                               total_equity_funding_amount_usd  \\\n",
       "Organization Name                                                \n",
       "CMC                                               1.600000e+09   \n",
       "Ping An Healthcare Management                     1.150000e+09   \n",
       "LeSee                                             1.080000e+09   \n",
       "\n",
       "                               total_funding_amount  total_funding_amount_usd  \\\n",
       "Organization Name                                                               \n",
       "CMC                                     10000000000              1.600000e+09   \n",
       "Ping An Healthcare Management            1150000000              1.150000e+09   \n",
       "LeSee                                    1080000000              1.080000e+09   \n",
       "\n",
       "                               female_led  \n",
       "Organization Name                          \n",
       "CMC                                     0  \n",
       "Ping An Healthcare Management           0  \n",
       "LeSee                                   0  \n",
       "\n",
       "[3 rows x 7353 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all top features based on pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('high_var_org_col_index.txt', 'r') as reader:\n",
    "    high_var_org_col_index = reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_var_org_col_index = ast.literal_eval(high_var_org_col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1352 = df[df.columns[high_var_org_col_index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1352\n",
    "y = df['female_led']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2055, 1: 142})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. random under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus, y_rus = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 142, 1: 142})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_train, X_rus_test, y_rus_train, y_rus_test = train_test_split(\n",
    "    X_rus, y_rus, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. random over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros, y_ros = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2055, 1: 2055})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros_train, X_ros_test, y_ros_train, y_ros_test = train_test_split(\n",
    "    X_ros, y_ros, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. tomek links under-sampling\n",
    "\n",
    "Tomek links are pairs of very close instances but of opposite classes. Removing the instances of the majority class of each pair increases the space between the two classes, facilitating the classification process.\n",
    "\n",
    "Tomekâ€™s link exists if the two samples are the nearest neighbors of each other\n",
    "\n",
    "![img](https://miro.medium.com/max/700/1*KxFmI15rxhvKRVl-febp-Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tl, y_tl = tl.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1968, 1: 142})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tl_train, X_tl_test, y_tl_train, y_tl_test = train_test_split(\n",
    "    X_tl, y_tl, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. synthetic minority over-sampling (SMOTE)\n",
    "\n",
    "This technique generates synthetic data for the minority class.\n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n",
    "\n",
    "![img](https://miro.medium.com/max/734/1*yRumRhn89acByodBz0H7oA.png)\n",
    "\n",
    "SMOTE algorithm works in 4 simple steps:\n",
    "\n",
    "1. Choose a minority class as the input vector\n",
    "2. Find its k nearest neighbors (k_neighbors is specified as an argument in the SMOTE() function)\n",
    "3. Choose one of these neighbors and place a synthetic point anywhere on the line joining the point under consideration and its chosen neighbor\n",
    "4. Repeat the steps until data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2055, 1: 2055})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(\n",
    "    X_smote, y_smote, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. NearMiss\n",
    "NearMiss is an under-sampling technique. Instead of resampling the Minority class, using a distance, this will make the majority class equal to the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = NearMiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nm, y_nm = nm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 142, 1: 142})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nm_train, X_nm_test, y_nm_train, y_nm_test = train_test_split(\n",
    "    X_nm, y_nm, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred) #perfect=1\n",
    "    precision = precision_score(y_true, y_pred) #perfect=1\n",
    "    recall = recall_score(y_true, y_pred) #perfect=1\n",
    "    f1 = f1_score(y_true, y_pred) #perfect=1\n",
    "#     roc_auc = roc_auc_score(y, clf.decision_function(X)) #perfect=1\n",
    "#     log = log_loss(y_true, y_pred) #perfect=0\n",
    "    mcc = matthews_corrcoef(y_true, y_pred) #perfect=1\n",
    "    kappa = cohen_kappa_score(y_true, y_pred) #perfect=1\n",
    "    \n",
    "#     print(f'accuracy={accuracy},\\\n",
    "#             precision={precision}, recall={recall}, \\\n",
    "#             f1={f1}, mcc={mcc}, kappa={kappa}')\n",
    "    \n",
    "#     return [accuracy, precision, recall]\n",
    "    return [accuracy, precision, recall, f1, mcc, kappa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_cols(xgb):\n",
    "    important_features_dict = xgb.get_booster().get_score(importance_type='weight')\n",
    "    return list(important_features_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_cols(xgb, n=50):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 15)\n",
    "    plot_importance(xgb, max_num_features=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. random under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6914893617021277,\n",
       " 0.6818181818181818,\n",
       " 0.6666666666666666,\n",
       " 0.6741573033707865,\n",
       " 0.3813850356982369,\n",
       " 0.3812982296867907]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rus = evaluate(xgb, X_rus_train, X_rus_test, y_rus_train, y_rus_test)\n",
    "metrics_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_rus = important_cols(xgb)\n",
    "len(cols_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_important_cols(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. random over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9815770081061165,\n",
       " 0.9633967789165446,\n",
       " 1.0,\n",
       " 0.9813571961222969,\n",
       " 0.9638156088600836,\n",
       " 0.9631613981403158]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ros = evaluate(xgb, X_ros_train, X_ros_test, y_ros_train, y_ros_test)\n",
    "metrics_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_ros = important_cols(xgb)\n",
    "len(cols_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_important_cols(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. tomet links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9253945480631277,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.02285726195738519,\n",
       " -0.013138033208475397]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_tl = evaluate(xgb, X_tl_train, X_tl_test, y_tl_train, y_tl_test)\n",
    "metrics_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_tl = important_cols(xgb)\n",
    "len(cols_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_important_cols(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9550478997789241,\n",
       " 0.9502262443438914,\n",
       " 0.9574468085106383,\n",
       " 0.9538228614685844,\n",
       " 0.9100584481338556,\n",
       " 0.9100337032613149]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_smote = evaluate(xgb, X_smote_train, X_smote_test, y_smote_train, y_smote_test)\n",
    "metrics_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_smote = important_cols(xgb)\n",
    "len(cols_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_important_cols(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. nearmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:38:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8191489361702128,\n",
       " 0.8333333333333334,\n",
       " 0.7777777777777778,\n",
       " 0.8045977011494253,\n",
       " 0.6379658352924606,\n",
       " 0.6366530241018645]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_nearmiss = evaluate(xgb, X_nm_train, X_nm_test, y_nm_train, y_nm_test)\n",
    "metrics_nearmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_nearmiss = important_cols(xgb)\n",
    "len(cols_nearmiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_important_cols(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "algos = ['rus', 'ros', 'tomet_links', 'smote', 'nearmiss']\n",
    "metrics_lst = [metrics_rus, metrics_ros, metrics_tl, metrics_smote, metrics_nearmiss]\n",
    "cols_lst = [cols_rus, cols_ros, cols_tl, cols_smote, cols_nearmiss]\n",
    "all_cols = list(df1352.columns)\n",
    "\n",
    "# set up\n",
    "metrics_data = []\n",
    "cols_data = []\n",
    "\n",
    "# loop through different weights\n",
    "for i in range(len(algos)):\n",
    "    \n",
    "    # get metrics\n",
    "    metrics_data.append(['xgboost_v5', f'{algos[i]}'] + metrics_lst[i])\n",
    "    \n",
    "    # get important columns\n",
    "    important_cols = cols_lst[i]\n",
    "    # one hot encode important cols in all columns dataframe\n",
    "    encoding = [1 if col in important_cols else 0 for col in all_cols]\n",
    "    cols_data.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics5 = pd.DataFrame(np.array(metrics_data),\n",
    "                columns=['model', 'setting', \n",
    "                'accuracy', 'precision', 'recall', 'f1', 'mcc', 'kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metrics5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols5 = pd.DataFrame(np.array(cols_data), columns=all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cols5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identified as important features by more than one method\n",
    "len(df_cols5.columns[df_cols5.sum()>2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics4 = pd.read_csv('../data/results_df/metrics_v4_dna.csv')\n",
    "df_cols4 = pd.read_csv('../data/results_df/important_cols_v4_dna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.concat([df_metrics4, df_metrics5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = pd.concat([df_cols4, df_cols5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metrics.to_csv('../data/results_df/metrics_v45_dna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cols.to_csv('../data/results_df/important_cols_v45_dna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Somehow the selected PCA columns also resulted in a very different feature selection in the xgboost model compared to the first time. \n",
    "- v1: 92/7532\n",
    "- v2: 6/100\n",
    "- v3: 48/1352\n",
    "- v4:  79/1352\n",
    "- v5: \n",
    "    - random under-sampling: 25/1352\n",
    "    - random over-sampling: 79/1352\n",
    "    - tomet links: 39/1352\n",
    "    - smote: 45/1352\n",
    "    - nearmiss: 21/1352\n",
    "\n",
    "v1-v3 does not deal with imbalance of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Differences\n",
    "\n",
    "model_version | feature selection | imbalanced class | hyperparameter tuning | cross validation\n",
    "--------------|-------------------|------------------|-----------------------|-----------------\n",
    "xgboost_v1 | no | no | no | no\n",
    "xgboost_v2 | yes, top100 | no | no | no\n",
    "xgboost_v3 | yes, top all 1352 | no | no | no\n",
    "xgboost_v4 | yes, top all 1352 | yes (weighted 20-50) | no | no\n",
    "xgboost_v5 | yes, top all 1352 | yes (under/over-sampling * 5) | no | no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
