{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "\n",
    "*dealing with multi-label columns, which generates the most columns*\n",
    "\n",
    "v3\n",
    "- instead of encoding the `female_led` info, just keep the percentage; if no information, encode **0.5**\n",
    "- no multilabelbinarizers\n",
    "\n",
    "v4\n",
    "- only keep the `Industry Groups` multilabel column\n",
    "\n",
    "v5\n",
    "- break down `Headquarters Location` multilabel column and use OneHotEncoder instead (similar to how `Headquarters Region` was processed\n",
    "\n",
    "v6 \n",
    "- strategically add `Top 5 Investors` information in after pre-processing, take investors appearing more than 10 times (added 78 more columns)\n",
    "\n",
    "v7\n",
    "- `Headquarters Location` expanded to also include cities\n",
    "- take `Top 5 Investors` appearing more than 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# feature engineering\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MultiLabelBinarizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aggregate Data\n",
    "combine data of regions China, Europe, and the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['China', 'Europe', 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f'../data/crunchbase-aggregated/{regions[0]}-gender.csv')\n",
    "df1 = pd.read_csv(f'../data/crunchbase-aggregated/{regions[1]}-gender.csv')\n",
    "df2 = pd.read_csv(f'../data/crunchbase-aggregated/{regions[2]}-gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 113)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df0, df1, df2])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Transformation\n",
    "data scaling, discretization, dealing missing values etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 skip rows\n",
    "\n",
    "1. rows already correctly labeled\n",
    "2. all the same or too many NULLs\n",
    "3. equivalent to name\n",
    "4. equivalent to total funding amount\n",
    "5. irrelevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_cols = ['Number of Founders', 'Number of Funding Rounds', \n",
    "              'Trend Score (7 Days)', 'Trend Score (30 Days)', 'Trend Score (90 Days)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Number of Founders': 'number_of_founders',\n",
    "                  'Number of Funding Rounds': 'number_of_funding_rounds',\n",
    "                  'Trend Score (7 Days)': 'trend_score_7',\n",
    "                  'Trend Score (30 Days)': 'trend_score_30',\n",
    "                  'Trend Score (90 Days)': 'trend_score_90'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Description', 'Full Description', \n",
    "             'Website', 'Twitter', 'Facebook', 'LinkedIn',\n",
    "             'Contact Email', 'Phone Number', 'Founders',\n",
    "             'Transaction Name', 'Contact Job Departments',\n",
    "             'Number of Contacts', 'Number of Private Contacts',\n",
    "             'api_raw', 'gender', 'prob',\n",
    "             'IPO Status', 'Operating Status', 'Diversity Spotlight (US Only)',\n",
    "              'Exit Date', 'Closed Date', 'Company Type', 'Hub Tags',\n",
    "              'Actively Hiring', 'Investor Type', 'Investment Stage',\n",
    "              'Number of Portfolio Organizations','Number of Investments',\n",
    "              'Number of Lead Investments', 'Number of Diversity Investments',\n",
    "              'Number of Exits', 'Number of Exits (IPO)', 'Accelerator Program Type',\n",
    "              'Accelerator Application Deadline', 'Accelerator Duration (in weeks)',\n",
    "              'School Type', 'School Program', 'Number of Enrollments',\n",
    "              'School Method', 'Number of Founders (Alumni)', 'Number of Alumni',\n",
    "              'Acquired by', 'Announced Date', 'Price', \n",
    "              'Acquisition Type', 'Acquisition Terms', 'Acquisition Status',\n",
    "              'IPO Date', 'Delisted Date', 'Money Raised at IPO',\n",
    "              'Valuation at IPO', 'Stock Symbol', 'Stock Exchange', 'Number of Events',\n",
    "              'Last Leadership Hiring Date', 'Last Layoff Mention Date',\n",
    "              'IT Spend', 'Date of Most Recent Valuation', 'Number of Private Notes', \n",
    "              'Most Popular Trademark Class', 'Most Popular Patent Class',\n",
    "              'Tags', 'Unnamed: 107', \n",
    "              'Industries', 'Funding Status', 'Last Equity Funding Type',\n",
    "              'CB Rank (Organization)', 'CB Rank (School)',\n",
    "              'Last Funding Amount', 'Last Equity Funding Amount', 'Total Equity Funding Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=drop_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 encoding categorical data\n",
    "### 2.2.1 convert text to equal categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**are they equal or ordinal?**\n",
    "- `Funding Status`: \"Early Stage Venture\", \"Seed\", \"M&A\" (overlaps with `Last Funding Type`)\n",
    "- `Acquisition Status`: \"Was Acquired\", \"Made Acquisitions\", \"Made Acquisitions; Was Acquired\" (for early stage too many NULLs)\n",
    "\n",
    "Notes\n",
    "- `Headquarters Location` _(city, state, country) where many city=state (e.g. New York)_ **(break it down, only take state and country, and use OneHotEncoder)**\n",
    "- `Headquarters Regions` (to avoid overlap with prev, only take last region and use OneHotEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess multi-label columns for one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headquarters regions\n",
    "df['hq_region'] = df['Headquarters Regions'].str.lower().str.strip('').str.split('; ').str[-1]\n",
    "df.drop(columns=['Headquarters Regions'], inplace=True)\n",
    "\n",
    "# headquarters location\n",
    "df['hq_country'] = df['Headquarters Location'].str.lower().str.strip('').str.split('; ').str[-1]\n",
    "df['hq_state'] = df['Headquarters Location'].str.lower().str.strip('').str.split('; ').str[-2]\n",
    "df['hq_city'] = df['Headquarters Location'].str.lower().str.strip('').str.split('; ').str[-3]\n",
    "df.drop(columns=['Headquarters Location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country==state\n",
    "state_country = list(df[df['hq_country']==df['hq_state']]['hq_state'].unique())\n",
    "\n",
    "# state==city\n",
    "error_cities = ['belgium', 'chongqing', 'guangdong', 'hunan', 'porto', 'tianjin', 'vaud', 'washington']\n",
    "state_city = list(df[df['hq_state']==df['hq_city']]['hq_state'].unique()) + error_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_cat(df, col):\n",
    "    \n",
    "    '''create new columns binary encoding each category'''\n",
    "    \n",
    "    # deal with NULL values\n",
    "    new_col = col.lower().replace(' ', '_')\n",
    "    df[new_col] = df[col].str.replace('—',f'{new_col}_null')\n",
    "    \n",
    "    # initiate binary encoder\n",
    "    ohe = OneHotEncoder()\n",
    "    \n",
    "    # join original df with the created df with many new binary columns\n",
    "    df_ohe = pd.DataFrame(ohe.fit_transform(asarray(df[new_col]).reshape(-1,1)).toarray(), \n",
    "                          columns=ohe.categories_, index=df.index)\n",
    "    df_ohe.columns = df_ohe.columns.get_level_values(0)\n",
    "    \n",
    "    # deal with exceptions\n",
    "    try:\n",
    "        df = df.join(df_ohe)\n",
    "    except ValueError:\n",
    "        # country==state\n",
    "        if col == 'hq_state':\n",
    "            df = df.join(df_ohe.drop(columns=state_country))\n",
    "        # state==city\n",
    "        if col == 'hq_city':\n",
    "            df = df.join(df_ohe.drop(columns=state_city))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 convert text to ORDINAL categories\n",
    "\n",
    "- 'Last Funding Type'\n",
    "- 'Estimated Revenue Range'\n",
    "- 'Number of Employees'\n",
    "- 'Most Recent Valuation Range'\n",
    "\n",
    "*Note: `.astype('category').cat.codes` is not a good method because it assigns the number in random order*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_cat(df, col):\n",
    "    \n",
    "    '''create one new column with ordinal categories'''\n",
    "    \n",
    "    # get text for new column name\n",
    "    new_col = col.lower().replace(' ', '_')\n",
    "    \n",
    "    \n",
    "    # specify ordinal order\n",
    "    if (col=='Last Funding Type'):\n",
    "        labels = ['Seed', 'Series A']\n",
    "    \n",
    "    if (col=='Estimated Revenue Range') or (col=='Most Recent Valuation Range'):\n",
    "        labels = ['—', 'Less than $1M', '$1M to $10M', '$10M to $50M', \n",
    "                  '$50M to $100M', '$100M to $500M', '$500M to $1B', \n",
    "                  '$1B to $10B', '$10B+']\n",
    "    \n",
    "    if col == 'Number of Employees':\n",
    "        # some '1-10' were read incorrectly and automatically converted to date formats\n",
    "        df['Number of Employees'] = df['Number of Employees'].str.replace('10-Jan', '1-10')\n",
    "        labels = ['—', '1-10', '11-50', '51-100', '101-250', '251-500', \n",
    "                  '501-1000', '1001-5000', '5001-10000', '10001+']\n",
    "    \n",
    "    \n",
    "    # convert text to ordinal categories\n",
    "    cat = list(np.array(labels).reshape(1,len(labels)))\n",
    "    oe = OrdinalEncoder(categories=cat)\n",
    "    df[new_col] = oe.fit_transform(asarray(df[col]).reshape(-1, 1))\n",
    "    df[new_col] = df[new_col].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 convert text list to MULTI-LABEL categories\n",
    "#1\n",
    "- `Headquarters Location` (after processing moved to OneHotEncoder)\n",
    "- `Headquarters Regions` (after processing moved to OneHotEncoder)\n",
    "\n",
    "#2\n",
    "- `Industries` (ignore because overlaps with `Industry Groups`)\n",
    "- `Industry Groups` \n",
    "\n",
    "#3\n",
    "- `Top 5 Investors` (after processing moved to OneHotEncoder)\n",
    "\n",
    "<span style=\"color:red\">\n",
    "create a new col called \"top_investors\" that is bool? --> can do this for \"top_industries\" too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all investors\n",
    "all_investors = []\n",
    "df_investors = df['Top 5 Investors'].str.lower().str.strip('').str.split('; ')\n",
    "for i in range(3000):\n",
    "    all_investors.extend(df_investors[i])\n",
    "    \n",
    "# len(all_investors) #8905\n",
    "# len(set(all_investors)) #4773\n",
    "\n",
    "# sorted(Counter(all_investors).items(), key=lambda pair: pair[1], reverse=True)\n",
    "# investors in at least 5 companies out of 3000\n",
    "top_investors = []\n",
    "for key, val in Counter(all_investors).items():\n",
    "    if val >= 5:\n",
    "        top_investors.append(key)\n",
    "\n",
    "# remove nan from list\n",
    "top_investors.remove('—')\n",
    "\n",
    "# one hot encode all these\n",
    "len(top_investors) #285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_cat(df, col):\n",
    "    '''create multiple one-hot encoded columns for each tag/label in a row'''\n",
    "    \n",
    "    # dealing with null valuess (so that null_cols for each newly created col is a different name)\n",
    "    new_col = col.lower().replace(' ', '_')\n",
    "    df[new_col] = df[col].str.replace('—', f'{new_col}_null')\n",
    "    \n",
    "    # get list of labels from text in each row\n",
    "    df[f'{new_col}_lst'] = df[new_col].str.lower().str.strip('').str.split('; ')\n",
    "    \n",
    "    # initiate multi-label binary encoder\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    \n",
    "    # join original df with the created df with many new binary columns\n",
    "    df_mlb = pd.DataFrame(mlb.fit_transform(df[f'{new_col}_lst']),\n",
    "                          columns=mlb.classes_, index=df.index)\n",
    "    \n",
    "    # only take top info to add back to table because investors info is sparse\n",
    "    if col=='Top 5 Investors':\n",
    "        df_mlb = df_mlb[top_investors]\n",
    "        \n",
    "    df = df.join(df_mlb)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 convert text to separate dates\n",
    "(1) have full date (format, e.g. \"Dec 31; 1999\"), \n",
    "(2) some have full date but most only have year\n",
    "\n",
    "- `Last Funding Date`: (1)\n",
    "- `Founded Date`: (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_date(df, col):\n",
    "    \n",
    "    '''create new columns separating date into day, month, year'''\n",
    "    \n",
    "    # (1) have full date info (format, e.g. \"Dec 31; 1999\")\n",
    "    if all(df[col].str.len()>10):\n",
    "    \n",
    "        # get text for new column name\n",
    "        new_col1 = col.lower().replace(' ', '_').replace('date', 'day')\n",
    "        new_col2 = col.lower().replace(' ', '_').replace('date', 'month')\n",
    "        new_col3 = col.lower().replace(' ', '_').replace('date', 'year')\n",
    "\n",
    "        # convert day and year\n",
    "        df[new_col3] = df[col].str[-4:]\n",
    "        df[new_col1] = df[col].str[3:5]\n",
    "\n",
    "        # convert month\n",
    "        # df[new_col2] = df[col].str[:3] #text\n",
    "        df[new_col2] = pd.to_datetime(df[col].str[:3], format='%b').dt.month\n",
    "    \n",
    "    \n",
    "    # (2) some rows have full date but most only have year info\n",
    "    else:\n",
    "        \n",
    "        # get text for new column name\n",
    "        new_col = col.lower().replace(' ', '_').replace('date', 'year')\n",
    "\n",
    "        # convert day and year\n",
    "        df[new_col] = df[col].str[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 convert text to number\n",
    "\n",
    "1. integer\n",
    "2. float (percentage)\n",
    "3. currency (multiply and union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_num(df, col, type='int'):\n",
    "    \n",
    "    '''update original column converting text to appropriate numerical format'''\n",
    "    \n",
    "    # get new column name\n",
    "    new_col = col.lower().replace(' ', '_')\n",
    "    \n",
    "    # common cleaning: deal with NULL values\n",
    "    df[new_col] = df[col].str.replace('—','0')\n",
    "    \n",
    "    # (1) integer\n",
    "    if type=='int':\n",
    "        \n",
    "        # convert text to int\n",
    "        df[new_col] = df[new_col].str.replace(';','').astype('int')\n",
    "        \n",
    "    # (2) float (percentage)\n",
    "    if type=='float':\n",
    "        \n",
    "        # additional step to strip sign\n",
    "        df[new_col] = df[new_col].str.replace('%','')\n",
    "        \n",
    "        # convert text to float\n",
    "        df[new_col].str.replace(';','').astype('float')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_curr(df, col):\n",
    "    '''create new column converting all amount to USD'''\n",
    "    \n",
    "    # get new column name\n",
    "    new_col = col.lower().replace(' ', '_')\n",
    "    \n",
    "    # clean text\n",
    "    df[new_col] = df[col].str.replace(';','')\n",
    "    \n",
    "    # add new col \"conversion rate\" of usd:currency = 1:x\n",
    "    df['cvr'] = 0\n",
    "    \n",
    "    # strip currency signs and update conversion rate\n",
    "    # us dollar\n",
    "    df[new_col] = df[new_col].str.replace('$','')\n",
    "    df.loc[df[col].str[0]=='$', 'cvr'] = 1\n",
    "    \n",
    "    # euro\n",
    "    df[new_col] = df[new_col].str.replace('€','')\n",
    "    df.loc[df[col].str[0]=='€', 'cvr'] = 1.1\n",
    "    \n",
    "    # uk pound\n",
    "    df[new_col] = df[new_col].str.replace('£','')\n",
    "    df.loc[df[col].str[0]=='£', 'cvr'] = 1.34\n",
    "    \n",
    "    # japanese yen\n",
    "    df[new_col] = df[new_col].str.replace('¥','')\n",
    "    df.loc[df[col].str[0]=='¥', 'cvr'] = 0.0087\n",
    "    \n",
    "    # chinese yuan ('CN¥')\n",
    "    df[new_col] = df[new_col].str.replace('CN','')\n",
    "    df.loc[df[col].str[0:2]=='CN', 'cvr'] = 0.16\n",
    "    \n",
    "    # canadian dollar ('CA$')\n",
    "    df[new_col] = df[new_col].str.replace('CA','')\n",
    "    df.loc[df[col].str[0:2]=='CA', 'cvr'] = 0.79\n",
    "    \n",
    "    # swiss franc\n",
    "    df[new_col] = df[new_col].str.replace('CHF','')\n",
    "    df.loc[df[col].str[0:3]=='CHF', 'cvr'] = 1.09\n",
    "    \n",
    "    # swedish krona\n",
    "    df[new_col] = df[new_col].str.replace('SEK','')\n",
    "    df.loc[df[col].str[0:3]=='SEK', 'cvr'] = 0.1\n",
    "    \n",
    "    # russian ruble\n",
    "    df[new_col] = df[new_col].str.replace('RUB','')\n",
    "    df.loc[df[col].str[0:3]=='RUB', 'cvr'] = 0.01\n",
    "        \n",
    "    # norwegian krone\n",
    "    df[new_col] = df[new_col].str.replace('NOK','')\n",
    "    df.loc[df[col].str[0:3]=='NOK', 'cvr'] = 0.11\n",
    "    \n",
    "    # new zealand dollar ('NZ$')\n",
    "    df[new_col] = df[new_col].str.replace('NZ','')\n",
    "    df.loc[df[col].str[0:2]=='NZ', 'cvr'] = 0.69\n",
    "    \n",
    "    # poland ztoty\n",
    "    df[new_col] = df[new_col].str.replace('PLN','')\n",
    "    df.loc[df[col].str[0:3]=='PLN', 'cvr'] = 0.24\n",
    "        \n",
    "    # icelandic krona\n",
    "    df[new_col] = df[new_col].str.replace('ISK','')\n",
    "    df.loc[df[col].str[0:3]=='ISK', 'cvr'] = 0.008\n",
    "    \n",
    "    # hungarian forint\n",
    "    df[new_col] = df[new_col].str.replace('HUF','')\n",
    "    df.loc[df[col].str[0:3]=='HUF', 'cvr'] = 0.003\n",
    "    \n",
    "    # null value\n",
    "    df[new_col] = df[new_col].str.replace('—','0')\n",
    "    \n",
    "    \n",
    "    '''cannot strip currency and convert to int the multipl only for parts of the data \n",
    "       so the best implementation is to split it into two steps'''\n",
    "    \n",
    "    # multiply number by conversion rate to get amount all in usd\n",
    "    df[new_col] = df[new_col].astype('int')\n",
    "    df[f'{new_col}_usd'] = df[new_col]*df['cvr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 convert text to NLP (bag of words?)\n",
    "- `Description`\n",
    "- `Full Description`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run all conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 54)\n",
      "(3000, 90)\n",
      "(3000, 311)\n",
      "(3000, 854)\n"
     ]
    }
   ],
   "source": [
    "# headquarters info all moved to equal_cats\n",
    "equal_cats = ['hq_region', 'hq_country', 'hq_state', 'hq_city']\n",
    "for cat1 in equal_cats:\n",
    "    df = equal_cat(df, cat1)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 858)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_cats = ['Last Funding Type', 'Estimated Revenue Range', 'Number of Employees', \n",
    "            'Most Recent Valuation Range']\n",
    "for cat2 in ord_cats:\n",
    "    ordinal_cat(df, cat2)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 862)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols = ['Last Funding Date', 'Founded Date']\n",
    "for date_col in date_cols:\n",
    "    text_date(df, date_col)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 877)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cols = ['CB Rank (Company)', 'Number of Articles', 'Number of Lead Investors', \n",
    "            'Number of Investors', 'Number of Acquisitions','Monthly Visits', \n",
    "            'Visit Duration', 'Global Traffic Rank', 'Monthly Rank Change (#)', \n",
    "            'Active Tech Count', 'Number of Apps', 'Downloads Last 30 Days',\n",
    "            'Total Products Active', 'Patents Granted', 'Trademarks Registered']\n",
    "for num1 in int_cols:\n",
    "        text_num(df, num1, type='int')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 885)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_cols = ['Monthly Visits Growth', 'Visit Duration Growth', 'Page Views / Visit', \n",
    "              'Page Views / Visit Growth', 'Bounce Rate', 'Bounce Rate Growth', \n",
    "              'Monthly Rank Growth', 'Average Visits (6 months)']\n",
    "for num2 in float_cols:\n",
    "    text_num(df, num2, type='float')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 888)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_cols = ['Total Funding Amount']\n",
    "for num3 in curr_cols:\n",
    "    text_curr(df, num3)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 938)\n",
      "(3000, 1225)\n"
     ]
    }
   ],
   "source": [
    "multi_cats = ['Industry Groups', 'Top 5 Investors']\n",
    "for cat3 in multi_cats:\n",
    "    df = multilabel_cat(df, cat3)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant cols generated from feature engineering\n",
    "multi_cats_lst = []\n",
    "for col in multi_cats:\n",
    "    new_col = col.lower().replace(' ', '_')\n",
    "    multi_cats_lst.append(f'{new_col}_lst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove additional cols\n",
    "- old cols that is no longer needed after new processing\n",
    "- midway processing cols used to produce new cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cols = equal_cats + ord_cats + multi_cats + multi_cats_lst + date_cols + int_cols + float_cols + curr_cols + ['cvr', 'total_funding_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1185)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=old_cols, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since no longer a classification task, `%female` can be kept as variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also drop the col that would give away\n",
    "df.drop(columns=['#female'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "encode no info as 0.5 in company (so it is a neutral situation? better than encoding 0?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['%female'].fillna(0.5, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_funding_amount_usd'].isnull().sum()#value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1184)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['total_funding_amount_usd']==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set name as index \n",
    "so that the rest of the columns are all numerical data that could fit in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1170)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('Organization Name', inplace=True)\n",
    "num_cols = df.describe().columns #this takes awhile to load\n",
    "new_df = df[num_cols]\n",
    "new_df.shape #v6: 423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df.columns).difference(set(new_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('../data/feature_engineering/combined_feng_v7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('../data/feature_engineering/combined_feng_reg.csv')\n",
    "# new_df.to_csv('../data/feature_engineering/combined_feng.csv')\n",
    "# new_df.to_csv('../data/feature_engineering/combined_feng_dropna.csv')\n",
    "# new_df.to_csv('../data/feature_engineering/combined_feng3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df['female_led'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
